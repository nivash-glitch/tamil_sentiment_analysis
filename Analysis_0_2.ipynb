{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nivash-glitch/tamil_sentiment_analysis/blob/main/Analysis_0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xYdReAb6Olr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "97dec6e8",
        "outputId": "42525d79-bd38-46ee-cdac-ea0199c9c0de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7b5780d-29d5-475e-83c9-51383b62622d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7b5780d-29d5-475e-83c9-51383b62622d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving filtered_sentiment_data.csv to filtered_sentiment_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ZrYusAX6otR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s9bYJnyj-gVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a729e36d-fd00-417c-f531-3d57f9b21514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "GPU: CPU only\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKKo-YmZ-sUh",
        "outputId": "9f603e6d-dd20-4dd8-f7c2-d452029816fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "Original dataset shape: (9919, 2)\n",
            "Original columns: ['text_preprocessed', 'sentiment']\n",
            "\n",
            "First few rows:\n",
            "                                   text_preprocessed sentiment\n",
            "0  ஒரு நாளும், ஒரு நாளும், ஒரு நாளும், ஒரு நாளும்...  Positive\n",
            "1  பன்னுவாங்காவைப் போலவே படத்தின் டிரைலரில் அஜித்...  Negative\n",
            "2  மன்காதா பில்போஸ் வார்ப்புரு ரேனையம் கலான்த்து ...  Positive\n",
            "3  அதன் ரோக்கிங்.. தேசார் நாலா இருகு.. ஆனால் படம்...  Positive\n",
            "4                யூ சூரியா வஸ்திரம் ஒரு பார் டென்டர்  Negative\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/filtered_sentiment_data.csv')\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"Original columns: {df.columns.tolist()}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JLqj_Um_bZ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07IOYpwq-t03",
        "outputId": "5e9e5ebe-f06a-419b-8972-a3b5b8c92be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "possible_text_cols = ['tweet', 'text', 'content', 'message', 'tamil_tweet', 'tamil_text', 'Tamil tweets','text_preprocessed']\n",
        "possible_label_cols = ['sentiment', 'label', 'class', 'category', 'Sentiment']\n",
        "\n",
        "text_col = None\n",
        "label_col = None\n",
        "\n",
        "# Find text column\n",
        "for col in df.columns:\n",
        "    if any(keyword.lower() in col.lower() for keyword in ['tweet', 'text', 'content', 'message', 'tamil']):\n",
        "        text_col = col\n",
        "        print(f\"Detected text column: '{col}'\")\n",
        "        break\n",
        "\n",
        "# Find label column\n",
        "for col in df.columns:\n",
        "    if any(keyword.lower() in col.lower() for keyword in ['sentiment', 'label', 'class', 'category']):\n",
        "        label_col = col\n",
        "        print(f\"Detected label column: '{col}'\")\n",
        "        break\n",
        "\n",
        "if not text_col or not label_col:\n",
        "    print(\"Could not auto-detect columns. Available columns:\")\n",
        "    for i, col in enumerate(df.columns):\n",
        "        print(f\"  {i}: {col}\")\n",
        "    print(\"\\nPlease manually specify in the next cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRuVJV7NzJzm",
        "outputId": "eb073b44-cd37-48de-d9d5-c77b5ecff572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected text column: 'text_preprocessed'\n",
            "Detected label column: 'sentiment'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if text_col and label_col:\n",
        "    df_renamed = df.rename(columns={text_col: 'text', label_col: 'label'})\n",
        "    print(f\"Renamed '{text_col}' → 'text'\")\n",
        "    print(f\"Renamed '{label_col}' → 'label'\")\n",
        "else:\n",
        "    # Manual column specification - adjust indices as needed\n",
        "    print(\"Manual column assignment (adjust if needed):\")\n",
        "    df_renamed = df.copy()\n",
        "    df_renamed.columns = ['text', 'label'] + list(df.columns[2:]) if len(df.columns) > 2 else ['text', 'label']\n",
        "    print(f\"Assigned columns: {df_renamed.columns.tolist()}\")\n",
        "\n",
        "print(f\"\\nRenamed dataset shape: {df_renamed.shape}\")\n",
        "print(f\"New columns: {df_renamed.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "isSo6ktv0ODE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8313c047-040e-4fda-accb-3a2b471641f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed 'text_preprocessed' → 'text'\n",
            "Renamed 'sentiment' → 'label'\n",
            "\n",
            "Renamed dataset shape: (9919, 2)\n",
            "New columns: ['text', 'label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" DATA EXPLORATION:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Text column sample:\")\n",
        "print(df_renamed['text'].head())\n",
        "print(f\"\\nLabel column unique values:\")\n",
        "print(df_renamed['label'].value_counts())\n",
        "print(f\"\\nSample text lengths:\")\n",
        "text_lengths = df_renamed['text'].str.len()\n",
        "print(f\"Min: {text_lengths.min()}, Max: {text_lengths.max()}, Mean: {text_lengths.mean():.1f}\")"
      ],
      "metadata": {
        "id": "8_ZbvthY0WdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5227845-d52c-4e55-8e6a-b07c5ea3dce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DATA EXPLORATION:\n",
            "========================================\n",
            "Text column sample:\n",
            "0    ஒரு நாளும், ஒரு நாளும், ஒரு நாளும், ஒரு நாளும்...\n",
            "1    பன்னுவாங்காவைப் போலவே படத்தின் டிரைலரில் அஜித்...\n",
            "2    மன்காதா பில்போஸ் வார்ப்புரு ரேனையம் கலான்த்து ...\n",
            "3    அதன் ரோக்கிங்.. தேசார் நாலா இருகு.. ஆனால் படம்...\n",
            "4                  யூ சூரியா வஸ்திரம் ஒரு பார் டென்டர்\n",
            "Name: text, dtype: object\n",
            "\n",
            "Label column unique values:\n",
            "label\n",
            "Negative    5163\n",
            "Positive    4756\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample text lengths:\n",
            "Min: 5, Max: 941, Mean: 63.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset before cleaning: {len(df_renamed)}\")\n",
        "\n",
        "df_clean = df_renamed.dropna(subset=['text', 'label'])\n",
        "print(f\"After removing NaN: {len(df_clean)}\")\n",
        "\n",
        "df_clean = df_clean[df_clean['text'].str.strip() != '']\n",
        "df_clean = df_clean[df_clean['label'].astype(str).str.strip() != '']\n",
        "print(f\"After removing empty strings: {len(df_clean)}\")\n",
        "\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "print(f\"Final cleaned dataset: {len(df_clean)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVuhbf1O5C6T",
        "outputId": "edf88721-6ac4-4d16-b81c-6b0e38073dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset before cleaning: 9919\n",
            "After removing NaN: 9919\n",
            "After removing empty strings: 9919\n",
            "Final cleaned dataset: 9919 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LABEL MAPPING:\")\n",
        "print(\"=\" * 30)\n",
        "print(\"Current unique labels:\")\n",
        "print(df_clean['label'].value_counts())\n",
        "\n",
        "label_mapping = {\n",
        "    'positive': 1, 'Positive': 1, 'POSITIVE': 1, 'pos': 1, 'POS': 1,\n",
        "    '1': 1, 1: 1, 'good': 1, 'Good': 1, 'GOOD': 1,\n",
        "    'happy': 1, 'Happy': 1, 'joy': 1, 'love': 1,\n",
        "\n",
        "    'negative': 0, 'Negative': 0, 'NEGATIVE': 0, 'neg': 0, 'NEG': 0,\n",
        "    '0': 0, 0: 0, 'bad': 0, 'Bad': 0, 'BAD': 0,\n",
        "    'sad': 0, 'Sad': 0, 'hate': 0, 'anger': 0\n",
        "}\n",
        "\n",
        "df_clean['binary_label'] = df_clean['label'].map(label_mapping)\n",
        "\n",
        "unmapped = df_clean[df_clean['binary_label'].isna()]\n",
        "if len(unmapped) > 0:\n",
        "    print(f\" Unmapped labels found: {unmapped['label'].unique()}\")\n",
        "    print(\"Assigning to negative (0) by default...\")\n",
        "\n",
        "df_clean['binary_label'] = df_clean['binary_label'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"\\n Binary label distribution:\")\n",
        "print(f\"Negative (0): {sum(df_clean['binary_label'] == 0)}\")\n",
        "print(f\"Positive (1): {sum(df_clean['binary_label'] == 1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuA43xOL0WrM",
        "outputId": "6b377a4f-792a-414a-d085-eef262c6938b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL MAPPING:\n",
            "==============================\n",
            "Current unique labels:\n",
            "label\n",
            "Negative    5163\n",
            "Positive    4756\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Binary label distribution:\n",
            "Negative (0): 5163\n",
            "Positive (1): 4756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Use the GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name = \"xlm-roberta-base\"\n",
        "print(f\"Loading {model_name}...\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "print(\"Tokenizer loaded\")\n",
        "\n",
        "# Load model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,  # binary sentiment\n",
        "    problem_type=\"single_label_classification\"\n",
        ")\n",
        "\n",
        "# Move model to GPU\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model ready on {device}\")\n",
        "print(f\"Model parameters: {model.num_parameters():,}\")\n"
      ],
      "metadata": {
        "id": "aaB54fl80W1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad049849-1b07-4583-f223-bff821ff270f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading xlm-roberta-base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded\n",
            "Model ready on cuda\n",
            "Model parameters: 278,045,186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TamilSentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, (list, np.ndarray)):\n",
        "            # Handle batch indexing\n",
        "            texts = [str(self.texts[i]) for i in idx]\n",
        "            labels = [self.labels[i] for i in idx]\n",
        "\n",
        "            encoding = self.tokenizer(\n",
        "                texts,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'input_ids': encoding['input_ids'],\n",
        "                'attention_mask': encoding['attention_mask'],\n",
        "                'labels': torch.tensor(labels, dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            # Handle single item indexing\n",
        "            text = str(self.texts[idx])\n",
        "            label = self.labels[idx]\n",
        "\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'input_ids': encoding['input_ids'].flatten(),\n",
        "                'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'labels': torch.tensor(label, dtype=torch.long)\n",
        "            }\n",
        "\n",
        "print(\"Dataset class defined\")"
      ],
      "metadata": {
        "id": "ktXyZE9e0xG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fb24be-f1f6-4fbd-9749-a9dda4f4148b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset class defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "hbekJ9iULp37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "\n",
        "# Total training steps = batches_per_epoch * epochs\n",
        "total_steps = len(dataloader) * epochs\n",
        "\n",
        "# Scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "print(epochs)"
      ],
      "metadata": {
        "id": "uonA5Hb907mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d43e40-b240-4866-e2bb-32a524ef16b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================\n",
        "# TRAINING CONFIGURATION\n",
        "# ============================================\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 3\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "warmup_ratio = 0.1\n",
        "gradient_accumulation_steps = 2\n",
        "\n",
        "# Calculate class weights\n",
        "class_counts = df_clean['binary_label'].value_counts().sort_index().values\n",
        "total_samples = len(df_clean)\n",
        "class_weights = torch.tensor([total_samples / (2 * count) for count in class_counts],\n",
        "                             dtype=torch.float).to(device)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Gradient accumulation: {gradient_accumulation_steps}\")\n",
        "print(f\"Effective batch size: {batch_size * gradient_accumulation_steps}\")\n",
        "print(f\"Epochs: {epochs}\")\n",
        "print(f\"Learning rate: {learning_rate}\")\n",
        "print(f\"Class weights: {class_weights.cpu().numpy()}\")\n",
        "print(f\"Total training samples: {len(train_texts)}\")\n",
        "\n",
        "# ============================================\n",
        "# CREATE DATALOADER\n",
        "# ============================================\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# OPTIMIZER AND SCHEDULER\n",
        "# ============================================\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs // gradient_accumulation_steps\n",
        "warmup_steps = int(warmup_ratio * total_steps)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "print(f\"Total training steps: {total_steps}\")\n",
        "print(f\"Warmup steps: {warmup_steps}\")\n",
        "\n",
        "# ============================================\n",
        "# TRAINING LOOP\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=\"Training\")\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, batch in enumerate(progress_bar):\n",
        "        # Move batch to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        # Apply class weights to loss\n",
        "        loss = outputs.loss\n",
        "        weighted_loss = loss * class_weights[labels].mean()\n",
        "        weighted_loss = weighted_loss / gradient_accumulation_steps\n",
        "\n",
        "        # Backward pass\n",
        "        weighted_loss.backward()\n",
        "\n",
        "        # Update weights every N steps\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
        "        })\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Save trained model\n",
        "output_dir = \"tamil_sentiment_xlm_roberta\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model saved to: {output_dir}\")\n",
        "\n",
        "# Now run your inference code...\n",
        "print(\"\\nStarting inference on Tamil texts...\")\n",
        "print(\"=\" * 50)\n"
      ],
      "metadata": {
        "id": "t0lG5eFV1DDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae046dc2-5bf7-4450-878d-ff81407b6878"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TRAINING CONFIGURATION\n",
            "============================================================\n",
            "Batch size: 16\n",
            "Gradient accumulation: 2\n",
            "Effective batch size: 32\n",
            "Epochs: 3\n",
            "Learning rate: 2e-05\n",
            "Class weights: [0.96058494 1.042788  ]\n",
            "Total training samples: 7935\n",
            "Total training steps: 744\n",
            "Warmup steps: 74\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "Epoch 1/3\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 496/496 [12:29<00:00,  1.51s/it, loss=0.6855, lr=1.48e-05]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 0.6871\n",
            "\n",
            "Epoch 2/3\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 496/496 [12:28<00:00,  1.51s/it, loss=0.5006, lr=7.40e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 0.6352\n",
            "\n",
            "Epoch 3/3\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 496/496 [12:28<00:00,  1.51s/it, loss=0.5383, lr=0.00e+00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 0.5768\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETED!\n",
            "============================================================\n",
            "Model saved to: tamil_sentiment_xlm_roberta\n",
            "\n",
            "Starting inference on Tamil texts...\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# EVALUATION METRICS AND PREDICTIONS\n",
        "# ============================================\n",
        "\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, classification_report, confusion_matrix)\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\nStarting inference on Tamil texts...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Prepare full dataset for inference\n",
        "full_dataset = TamilSentimentDataset(\n",
        "    df_clean['text'].tolist(),\n",
        "    df_clean['binary_label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "full_dataloader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size * 2,  # Larger batch for inference\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Run inference\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_probabilities = []\n",
        "all_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(full_dataloader, desc=\"Processing batches\"):\n",
        "        # Move batch to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels']\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Get probabilities and predictions\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        # Store results\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_probabilities.extend(probabilities.cpu().numpy())\n",
        "        all_true_labels.extend(labels.numpy())\n",
        "\n",
        "print(\"Inference completed!\")\n",
        "print(f\"Processed {len(all_predictions)} samples\\n\")\n",
        "\n",
        "# ============================================\n",
        "# CALCULATE EVALUATION METRICS\n",
        "# ============================================\n",
        "\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_probabilities = np.array(all_probabilities)\n",
        "all_true_labels = np.array(all_true_labels)\n",
        "\n",
        "# Core metrics\n",
        "accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "precision = precision_score(all_true_labels, all_predictions, average='weighted')\n",
        "recall = recall_score(all_true_labels, all_predictions, average='weighted')\n",
        "f1 = f1_score(all_true_labels, all_predictions, average='weighted')\n",
        "\n",
        "# Macro metrics (for imbalanced data)\n",
        "macro_precision = precision_score(all_true_labels, all_predictions, average='macro')\n",
        "macro_recall = recall_score(all_true_labels, all_predictions, average='macro')\n",
        "macro_f1 = f1_score(all_true_labels, all_predictions, average='macro')\n",
        "\n",
        "# Per-class metrics\n",
        "precision_per_class = precision_score(all_true_labels, all_predictions, average=None)\n",
        "recall_per_class = recall_score(all_true_labels, all_predictions, average=None)\n",
        "f1_per_class = f1_score(all_true_labels, all_predictions, average=None)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"EVALUATION METRICS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{'Metric':<25} {'Value':>10}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Accuracy':<25} {accuracy:>10.3f}\")\n",
        "print(f\"{'Weighted Precision':<25} {precision:>10.3f}\")\n",
        "print(f\"{'Weighted Recall':<25} {recall:>10.3f}\")\n",
        "print(f\"{'Weighted F1-Score':<25} {f1:>10.3f}\")\n",
        "print(f\"\\n{'Macro Precision':<25} {macro_precision:>10.3f}\")\n",
        "print(f\"{'Macro Recall':<25} {macro_recall:>10.3f}\")\n",
        "print(f\"{'Macro F1-Score':<25} {macro_f1:>10.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PER-CLASS METRICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{'Class':<15} {'Precision':>12} {'Recall':>12} {'F1-Score':>12}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Negative':<15} {precision_per_class[0]:>12.3f} {recall_per_class[0]:>12.3f} {f1_per_class[0]:>12.3f}\")\n",
        "print(f\"{'Positive':<15} {precision_per_class[1]:>12.3f} {recall_per_class[1]:>12.3f} {f1_per_class[1]:>12.3f}\")\n",
        "\n",
        "# ============================================\n",
        "# DETAILED CLASSIFICATION REPORT\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(classification_report(\n",
        "    all_true_labels,\n",
        "    all_predictions,\n",
        "    target_names=['Negative', 'Positive'],\n",
        "    digits=3\n",
        "))\n",
        "\n",
        "# ============================================\n",
        "# CONFUSION MATRIX\n",
        "# ============================================\n",
        "\n",
        "cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "print(\"=\" * 60)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{'':>15} {'Predicted Neg':>15} {'Predicted Pos':>15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Actual Neg':<15} {cm[0][0]:>15} {cm[0][1]:>15}\")\n",
        "print(f\"{'Actual Pos':<15} {cm[1][0]:>15} {cm[1][1]:>15}\")\n",
        "\n",
        "# ============================================\n",
        "# PREDICTION DISTRIBUTION\n",
        "# ============================================\n",
        "\n",
        "neg_count = np.sum(all_predictions == 0)\n",
        "pos_count = np.sum(all_predictions == 1)\n",
        "avg_confidence = np.max(all_probabilities, axis=1).mean()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PREDICTION DISTRIBUTION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total samples: {len(all_predictions)}\")\n",
        "print(f\"Predicted Negative: {neg_count} ({neg_count/len(all_predictions)*100:.1f}%)\")\n",
        "print(f\"Predicted Positive: {pos_count} ({pos_count/len(all_predictions)*100:.1f}%)\")\n",
        "print(f\"Average confidence: {avg_confidence:.3f}\")\n",
        "\n",
        "# ============================================\n",
        "# SAMPLE PREDICTIONS\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SAMPLE PREDICTIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Show 10 sample predictions\n",
        "sample_indices = np.random.choice(len(all_predictions), min(10, len(all_predictions)), replace=False)\n",
        "label_map = {0: 'Negative', 1: 'Positive'}\n",
        "\n",
        "for i, idx in enumerate(sample_indices, 1):\n",
        "    text = df_clean.iloc[idx]['text']\n",
        "    true_label = all_true_labels[idx]\n",
        "    pred_label = all_predictions[idx]\n",
        "    neg_prob = all_probabilities[idx][0]\n",
        "    pos_prob = all_probabilities[idx][1]\n",
        "\n",
        "    print(f\"\\nSample {i}:\")\n",
        "    print(f\"Text: {text[:80]}{'...' if len(text) > 80 else ''}\")\n",
        "    print(f\"True: {label_map[true_label]} | Predicted: {label_map[pred_label]}\")\n",
        "    print(f\"Confidence: {max(neg_prob, pos_prob):.3f}\")\n",
        "    print(f\"Pos: {pos_prob:.3f} | Neg: {neg_prob:.3f}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# ============================================\n",
        "# ERROR ANALYSIS\n",
        "# ============================================\n",
        "\n",
        "# Find misclassified samples\n",
        "misclassified_indices = np.where(all_predictions != all_true_labels)[0]\n",
        "misclassification_rate = len(misclassified_indices) / len(all_predictions)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total misclassifications: {len(misclassified_indices)}\")\n",
        "print(f\"Misclassification rate: {misclassification_rate:.3f} ({misclassification_rate*100:.1f}%)\")\n",
        "\n",
        "# False positives and false negatives\n",
        "false_positives = np.where((all_predictions == 1) & (all_true_labels == 0))[0]\n",
        "false_negatives = np.where((all_predictions == 0) & (all_true_labels == 1))[0]\n",
        "\n",
        "print(f\"\\nFalse Positives: {len(false_positives)} ({len(false_positives)/len(all_predictions)*100:.1f}%)\")\n",
        "print(f\"False Negatives: {len(false_negatives)} ({len(false_negatives)/len(all_predictions)*100:.1f}%)\")\n",
        "\n",
        "# Show worst predictions (low confidence misclassifications)\n",
        "if len(misclassified_indices) > 0:\n",
        "    misclassified_confidences = np.max(all_probabilities[misclassified_indices], axis=1)\n",
        "    worst_indices = misclassified_indices[np.argsort(misclassified_confidences)[:5]]\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 60)\n",
        "    print(\"TOP 5 MISCLASSIFICATIONS (Lowest Confidence):\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for i, idx in enumerate(worst_indices, 1):\n",
        "        text = df_clean.iloc[idx]['text']\n",
        "        true_label = all_true_labels[idx]\n",
        "        pred_label = all_predictions[idx]\n",
        "        confidence = np.max(all_probabilities[idx])\n",
        "\n",
        "        print(f\"\\n{i}. Text: {text[:60]}...\")\n",
        "        print(f\"   True: {label_map[true_label]} | Predicted: {label_map[pred_label]}\")\n",
        "        print(f\"   Confidence: {confidence:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EVALUATION COMPLETE!\")\n",
        "print(\"=\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y4cUYfR3VaB",
        "outputId": "a0c6aaaa-67d7-42d7-f617-57666672f24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting inference on Tamil texts...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 310/310 [04:35<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference completed!\n",
            "Processed 9919 samples\n",
            "\n",
            "============================================================\n",
            "EVALUATION METRICS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Metric                         Value\n",
            "------------------------------------------------------------\n",
            "Accuracy                       0.739\n",
            "Weighted Precision             0.739\n",
            "Weighted Recall                0.739\n",
            "Weighted F1-Score              0.739\n",
            "\n",
            "Macro Precision                0.738\n",
            "Macro Recall                   0.738\n",
            "Macro F1-Score                 0.738\n",
            "\n",
            "============================================================\n",
            "PER-CLASS METRICS\n",
            "============================================================\n",
            "\n",
            "Class              Precision       Recall     F1-Score\n",
            "------------------------------------------------------------\n",
            "Negative               0.747        0.753        0.750\n",
            "Positive               0.730        0.723        0.726\n",
            "\n",
            "============================================================\n",
            "CLASSIFICATION REPORT\n",
            "============================================================\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative      0.747     0.753     0.750      5163\n",
            "    Positive      0.730     0.723     0.726      4756\n",
            "\n",
            "    accuracy                          0.739      9919\n",
            "   macro avg      0.738     0.738     0.738      9919\n",
            "weighted avg      0.739     0.739     0.739      9919\n",
            "\n",
            "============================================================\n",
            "CONFUSION MATRIX\n",
            "============================================================\n",
            "\n",
            "                  Predicted Neg   Predicted Pos\n",
            "------------------------------------------------------------\n",
            "Actual Neg                 3889            1274\n",
            "Actual Pos                 1317            3439\n",
            "\n",
            "============================================================\n",
            "PREDICTION DISTRIBUTION\n",
            "============================================================\n",
            "Total samples: 9919\n",
            "Predicted Negative: 5206 (52.5%)\n",
            "Predicted Positive: 4713 (47.5%)\n",
            "Average confidence: 0.764\n",
            "\n",
            "============================================================\n",
            "SAMPLE PREDICTIONS\n",
            "============================================================\n",
            "\n",
            "Sample 1:\n",
            "Text: இப்பெயின் விரும்பும் பாத்திரங்கள் எடுப்பதைப் போல் பாத்திரங்கள் வார்ங்கெல்\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.765\n",
            "Pos: 0.235 | Neg: 0.765\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 2:\n",
            "Text: ஏ.. முதல் காட்சி வரையறுக்கவும், முதல் காட்சி வரையறுக்கவும், முதல் காட்சி வரையறுக...\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.767\n",
            "Pos: 0.233 | Neg: 0.767\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 3:\n",
            "Text: டய மட்டக்களப்பு டய மட்டக்களப்பு டய மட்டக்களப்பு.\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.804\n",
            "Pos: 0.196 | Neg: 0.804\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 4:\n",
            "Text: உதயநிதி அண்ணா உங்குளூ உடு கேடச்சுருகு எல்லாம் சிறப்பாகட்டும்.\n",
            "True: Positive | Predicted: Positive\n",
            "Confidence: 0.823\n",
            "Pos: 0.823 | Neg: 0.177\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 5:\n",
            "Text: தமிழ்நாட்டில் பங்கேற்பதை விட பங்கேற்பதை அதிகரிப்பேன், பங்கேற்பதை அதிகரிப்பேன், ப...\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.706\n",
            "Pos: 0.294 | Neg: 0.706\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 6:\n",
            "Text: யாபா சாமி முன்னே தேசர் பத்மனோ இருகு!!\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.808\n",
            "Pos: 0.192 | Neg: 0.808\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 7:\n",
            "Text: இரண்டாம் பாகத்தை எதிர்பார்த்துக் கொண்டிருக்கும் பத்மியலயீ விரீதனம் மா இருகூ\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.525\n",
            "Pos: 0.475 | Neg: 0.525\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 8:\n",
            "Text: வர்த்தயாலா சோலா தேலா செம்மயா இருகூர் சுரியா அண்ணா\n",
            "True: Positive | Predicted: Positive\n",
            "Confidence: 0.865\n",
            "Pos: 0.865 | Neg: 0.135\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 9:\n",
            "Text: இரைன்காடா !! நாலா பின்வாங்கும் பான்னி பட்குரன் !! எதே பாகன்மு டெர்ல் ..பிறகு வார...\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.570\n",
            "Pos: 0.430 | Neg: 0.570\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sample 10:\n",
            "Text: அய்யோ இன்தா மனோசனு உம்மையாவே வயதில் என் நானோ திரிலா பா ஈபாடி இருகுரு தலபதி ரசிகர...\n",
            "True: Negative | Predicted: Negative\n",
            "Confidence: 0.596\n",
            "Pos: 0.404 | Neg: 0.596\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "ERROR ANALYSIS\n",
            "============================================================\n",
            "Total misclassifications: 2591\n",
            "Misclassification rate: 0.261 (26.1%)\n",
            "\n",
            "False Positives: 1274 (12.8%)\n",
            "False Negatives: 1317 (13.3%)\n",
            "\n",
            "------------------------------------------------------------\n",
            "TOP 5 MISCLASSIFICATIONS (Lowest Confidence):\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. Text: பருவநிலை மாற்றங்கள்...\n",
            "   True: Positive | Predicted: Negative\n",
            "   Confidence: 0.500\n",
            "\n",
            "2. Text: பண்டிரவங்கா எத்தனா பெருவை எதிர்பார்த்துப் பார்யுங்கள்!!...\n",
            "   True: Positive | Predicted: Negative\n",
            "   Confidence: 0.500\n",
            "\n",
            "3. Text: பண்டிரவங்கா எத்தனா பெருவை எதிர்பார்த்துப் பார்யுங்கள்!!...\n",
            "   True: Positive | Predicted: Negative\n",
            "   Confidence: 0.500\n",
            "\n",
            "4. Text: 1:23 விஜய் அவாச்சூ சென்சிங் காட்சி...\n",
            "   True: Positive | Predicted: Negative\n",
            "   Confidence: 0.500\n",
            "\n",
            "5. Text: அஜித்: நீரியா நீரியா நீரியா நீரியா நீரியா நீதிபதி: திரு.வந்த...\n",
            "   True: Negative | Predicted: Positive\n",
            "   Confidence: 0.500\n",
            "\n",
            "============================================================\n",
            "EVALUATION COMPLETE!\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# EXAMPLE PREDICTIONS ON NEW TAMIL TEXTS\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def predict_sentiment(texts, model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Predict sentiment for a list of Tamil texts\n",
        "\n",
        "    Args:\n",
        "        texts: List of Tamil text strings\n",
        "        model: Trained sentiment model\n",
        "        tokenizer: XLM-RoBERTa tokenizer\n",
        "        device: torch device (cuda/cpu)\n",
        "\n",
        "    Returns:\n",
        "        predictions, probabilities, and labels\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text in texts:\n",
        "            # Tokenize\n",
        "            encoding = tokenizer(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=128,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "            # Predict\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get probabilities\n",
        "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            prediction = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "            neg_prob = probabilities[0][0].item()\n",
        "            pos_prob = probabilities[0][1].item()\n",
        "            confidence = max(neg_prob, pos_prob)\n",
        "\n",
        "            sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
        "\n",
        "            results.append({\n",
        "                'text': text,\n",
        "                'sentiment': sentiment,\n",
        "                'confidence': confidence,\n",
        "                'positive_prob': pos_prob,\n",
        "                'negative_prob': neg_prob\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# TEST EXAMPLES - TAMIL SENTIMENT TEXTS\n",
        "# ============================================\n",
        "\n",
        "# Positive Examples\n",
        "positive_examples = [\n",
        "    \"இந்த திரைப்படம் மிகவும் அருமையாக இருந்தது\",  # This movie was very good\n",
        "    \"இது சிறந்த உணவகம், உணவு மிகவும் சுவையாக இருந்தது\",  # Great restaurant, food was delicious\n",
        "    \"நான் மிகவும் மகிழ்ச்சியாக இருக்கிறேன்\",  # I am very happy\n",
        "    \"அருமையான சேவை, நன்றி\",  # Excellent service, thank you\n",
        "    \"இந்த தொலைபேசி மிகவும் நன்றாக வேலை செய்கிறது\",  # This phone works very well\n",
        "    \"என் வாழ்க்கையில் சிறந்த நாள்\",  # Best day of my life\n",
        "    \"இந்த புத்தகம் படிக்க மிகவும் சுவாரஸ்யமாக இருந்தது\",  # This book was very interesting to read\n",
        "    \"ஆசிரியர் மிகவும் நன்றாக கற்பித்தார்\",  # Teacher taught very well\n",
        "]\n",
        "\n",
        "# Negative Examples\n",
        "negative_examples = [\n",
        "    \"இந்த தொலைபேசி கேமரா நன்றாக இல்லை\",  # This phone camera is not good\n",
        "    \"மோசமான சேவை, மிகவும் விலை அதிகம்\",  # Bad service, very expensive\n",
        "    \"இந்த உணவு சுவையற்றது\",  # This food is tasteless\n",
        "    \"நான் மிகவும் வருத்தமாக இருக்கிறேன்\",  # I am very sad\n",
        "    \"இது வீணான பணம்\",  # This is wasted money\n",
        "    \"திரைப்படம் மிகவும் மோசமாக இருந்தது\",  # Movie was very bad\n",
        "    \"தரம் மிகவும் மோசமானது\",  # Quality is very poor\n",
        "    \"நான் படிக்கவில்லை, தோல்வியடைந்தேன்\",  # I did not study, I failed\n",
        "]\n",
        "\n",
        "# Mixed/Neutral Examples\n",
        "mixed_examples = [\n",
        "    \"திரைப்படம் நன்றாக இருந்தது ஆனால் முடிவு சரியில்லை\",  # Movie was good but ending was not right\n",
        "    \"உணவு சுவையாக இருந்தது ஆனால் சேவை மெதுவாக இருந்தது\",  # Food was tasty but service was slow\n",
        "    \"சில பகுதிகள் நல்லது, சில பகுதிகள் மோசம்\",  # Some parts good, some parts bad\n",
        "]\n",
        "\n",
        "# Code-Mixed Tamil-English (Tanglish) Examples\n",
        "tanglish_examples = [\n",
        "    \"super movie, romba nalla irunthathu\",  # Super movie, was very good\n",
        "    \"worst experience, never going back\",  # Worst experience, never going back\n",
        "    \"food taste illa, waste of money\",  # Food has no taste, waste of money\n",
        "    \"best hotel in Chennai, must try\",  # Best hotel in Chennai, must try\n",
        "]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TESTING MODEL ON TAMIL SENTIMENT EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================\n",
        "# TEST POSITIVE EXAMPLES\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POSITIVE EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "positive_results = predict_sentiment(positive_examples, model, tokenizer, device)\n",
        "\n",
        "for i, result in enumerate(positive_results, 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Text: {result['text']}\")\n",
        "    print(f\"Predicted: {result['sentiment']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "    print(f\"Positive: {result['positive_prob']:.3f} | Negative: {result['negative_prob']:.3f}\")\n",
        "\n",
        "    # Check if prediction is correct\n",
        "    if result['sentiment'] == 'Positive':\n",
        "        print(\"✓ CORRECT\")\n",
        "    else:\n",
        "        print(\"✗ INCORRECT (Should be Positive)\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_positive = sum(1 for r in positive_results if r['sentiment'] == 'Positive')\n",
        "positive_accuracy = correct_positive / len(positive_results)\n",
        "print(f\"\\nPositive Examples Accuracy: {positive_accuracy:.2%} ({correct_positive}/{len(positive_results)})\")\n",
        "\n",
        "# ============================================\n",
        "# TEST NEGATIVE EXAMPLES\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"NEGATIVE EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "negative_results = predict_sentiment(negative_examples, model, tokenizer, device)\n",
        "\n",
        "for i, result in enumerate(negative_results, 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Text: {result['text']}\")\n",
        "    print(f\"Predicted: {result['sentiment']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "    print(f\"Positive: {result['positive_prob']:.3f} | Negative: {result['negative_prob']:.3f}\")\n",
        "\n",
        "    # Check if prediction is correct\n",
        "    if result['sentiment'] == 'Negative':\n",
        "        print(\"✓ CORRECT\")\n",
        "    else:\n",
        "        print(\"✗ INCORRECT (Should be Negative)\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_negative = sum(1 for r in negative_results if r['sentiment'] == 'Negative')\n",
        "negative_accuracy = correct_negative / len(negative_results)\n",
        "print(f\"\\nNegative Examples Accuracy: {negative_accuracy:.2%} ({correct_negative}/{len(negative_results)})\")\n",
        "\n",
        "# ============================================\n",
        "# TEST MIXED EXAMPLES\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MIXED/NEUTRAL EXAMPLES (Expected: Variable)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "mixed_results = predict_sentiment(mixed_examples, model, tokenizer, device)\n",
        "\n",
        "for i, result in enumerate(mixed_results, 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Text: {result['text']}\")\n",
        "    print(f\"Predicted: {result['sentiment']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "    print(f\"Positive: {result['positive_prob']:.3f} | Negative: {result['negative_prob']:.3f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# ============================================\n",
        "# TEST TANGLISH (CODE-MIXED) EXAMPLES\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TANGLISH (CODE-MIXED TAMIL-ENGLISH) EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "tanglish_results = predict_sentiment(tanglish_examples, model, tokenizer, device)\n",
        "\n",
        "for i, result in enumerate(tanglish_results, 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Text: {result['text']}\")\n",
        "    print(f\"Predicted: {result['sentiment']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "    print(f\"Positive: {result['positive_prob']:.3f} | Negative: {result['negative_prob']:.3f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# ============================================\n",
        "# OVERALL SUMMARY\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"OVERALL TESTING SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "total_correct = correct_positive + correct_negative\n",
        "total_tested = len(positive_examples) + len(negative_examples)\n",
        "overall_accuracy = total_correct / total_tested\n",
        "\n",
        "print(f\"\\nPositive Examples: {positive_accuracy:.1%} correct\")\n",
        "print(f\"Negative Examples: {negative_accuracy:.1%} correct\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.1%} ({total_correct}/{total_tested})\")\n",
        "\n",
        "# Average confidence scores\n",
        "all_results = positive_results + negative_results\n",
        "avg_confidence = np.mean([r['confidence'] for r in all_results])\n",
        "print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iVerwHY3VSY",
        "outputId": "ebe3d34a-ec56-4113-9de3-7c8c62cd02df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TESTING MODEL ON TAMIL SENTIMENT EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "POSITIVE EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "Example 1:\n",
            "Text: இந்த திரைப்படம் மிகவும் அருமையாக இருந்தது\n",
            "Predicted: Positive\n",
            "Confidence: 0.785\n",
            "Positive: 0.785 | Negative: 0.215\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Text: இது சிறந்த உணவகம், உணவு மிகவும் சுவையாக இருந்தது\n",
            "Predicted: Positive\n",
            "Confidence: 0.610\n",
            "Positive: 0.610 | Negative: 0.390\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Text: நான் மிகவும் மகிழ்ச்சியாக இருக்கிறேன்\n",
            "Predicted: Positive\n",
            "Confidence: 0.899\n",
            "Positive: 0.899 | Negative: 0.101\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "Text: அருமையான சேவை, நன்றி\n",
            "Predicted: Positive\n",
            "Confidence: 0.898\n",
            "Positive: 0.898 | Negative: 0.102\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 5:\n",
            "Text: இந்த தொலைபேசி மிகவும் நன்றாக வேலை செய்கிறது\n",
            "Predicted: Positive\n",
            "Confidence: 0.602\n",
            "Positive: 0.602 | Negative: 0.398\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 6:\n",
            "Text: என் வாழ்க்கையில் சிறந்த நாள்\n",
            "Predicted: Positive\n",
            "Confidence: 0.887\n",
            "Positive: 0.887 | Negative: 0.113\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 7:\n",
            "Text: இந்த புத்தகம் படிக்க மிகவும் சுவாரஸ்யமாக இருந்தது\n",
            "Predicted: Positive\n",
            "Confidence: 0.799\n",
            "Positive: 0.799 | Negative: 0.201\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 8:\n",
            "Text: ஆசிரியர் மிகவும் நன்றாக கற்பித்தார்\n",
            "Predicted: Positive\n",
            "Confidence: 0.885\n",
            "Positive: 0.885 | Negative: 0.115\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Positive Examples Accuracy: 100.00% (8/8)\n",
            "\n",
            "================================================================================\n",
            "NEGATIVE EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "Example 1:\n",
            "Text: இந்த தொலைபேசி கேமரா நன்றாக இல்லை\n",
            "Predicted: Negative\n",
            "Confidence: 0.573\n",
            "Positive: 0.427 | Negative: 0.573\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Text: மோசமான சேவை, மிகவும் விலை அதிகம்\n",
            "Predicted: Negative\n",
            "Confidence: 0.655\n",
            "Positive: 0.345 | Negative: 0.655\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Text: இந்த உணவு சுவையற்றது\n",
            "Predicted: Negative\n",
            "Confidence: 0.760\n",
            "Positive: 0.240 | Negative: 0.760\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "Text: நான் மிகவும் வருத்தமாக இருக்கிறேன்\n",
            "Predicted: Positive\n",
            "Confidence: 0.901\n",
            "Positive: 0.901 | Negative: 0.099\n",
            "✗ INCORRECT (Should be Negative)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 5:\n",
            "Text: இது வீணான பணம்\n",
            "Predicted: Negative\n",
            "Confidence: 0.683\n",
            "Positive: 0.317 | Negative: 0.683\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 6:\n",
            "Text: திரைப்படம் மிகவும் மோசமாக இருந்தது\n",
            "Predicted: Negative\n",
            "Confidence: 0.640\n",
            "Positive: 0.360 | Negative: 0.640\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 7:\n",
            "Text: தரம் மிகவும் மோசமானது\n",
            "Predicted: Negative\n",
            "Confidence: 0.594\n",
            "Positive: 0.406 | Negative: 0.594\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 8:\n",
            "Text: நான் படிக்கவில்லை, தோல்வியடைந்தேன்\n",
            "Predicted: Negative\n",
            "Confidence: 0.663\n",
            "Positive: 0.337 | Negative: 0.663\n",
            "✓ CORRECT\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Negative Examples Accuracy: 87.50% (7/8)\n",
            "\n",
            "================================================================================\n",
            "MIXED/NEUTRAL EXAMPLES (Expected: Variable)\n",
            "================================================================================\n",
            "\n",
            "Example 1:\n",
            "Text: திரைப்படம் நன்றாக இருந்தது ஆனால் முடிவு சரியில்லை\n",
            "Predicted: Negative\n",
            "Confidence: 0.665\n",
            "Positive: 0.335 | Negative: 0.665\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Text: உணவு சுவையாக இருந்தது ஆனால் சேவை மெதுவாக இருந்தது\n",
            "Predicted: Negative\n",
            "Confidence: 0.674\n",
            "Positive: 0.326 | Negative: 0.674\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Text: சில பகுதிகள் நல்லது, சில பகுதிகள் மோசம்\n",
            "Predicted: Negative\n",
            "Confidence: 0.660\n",
            "Positive: 0.340 | Negative: 0.660\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "TANGLISH (CODE-MIXED TAMIL-ENGLISH) EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "Example 1:\n",
            "Text: super movie, romba nalla irunthathu\n",
            "Predicted: Negative\n",
            "Confidence: 0.544\n",
            "Positive: 0.456 | Negative: 0.544\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Text: worst experience, never going back\n",
            "Predicted: Negative\n",
            "Confidence: 0.598\n",
            "Positive: 0.402 | Negative: 0.598\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Text: food taste illa, waste of money\n",
            "Predicted: Negative\n",
            "Confidence: 0.661\n",
            "Positive: 0.339 | Negative: 0.661\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "Text: best hotel in Chennai, must try\n",
            "Predicted: Positive\n",
            "Confidence: 0.759\n",
            "Positive: 0.759 | Negative: 0.241\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "OVERALL TESTING SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Positive Examples: 100.0% correct\n",
            "Negative Examples: 87.5% correct\n",
            "Overall Accuracy: 93.8% (15/16)\n",
            "Average Confidence: 0.740\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elQST5ac3VOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GC4VFFPX3VC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNe05wBpMIepdYWS+/fRg2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}